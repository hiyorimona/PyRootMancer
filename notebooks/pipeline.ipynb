{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.morphology import skeletonize\n",
    "from tensorflow.keras.models import load_model\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('E:/Github/2023-24d-fai2-adsai-group-cv5/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5988397598922190281\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5826936832\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16251346356298847801\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from src.models.model_work import ModelWork\n",
    "from src.models.model_evaluation import iou, f1\n",
    "from src.data.data_preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = DataPipelineSetup()\n",
    "model_work = ModelWork()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at e:\\Github\\2023-24d-fai2-adsai-group-cv5\\models\\your_model_name.keras",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load your trained model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_work\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myour_model_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# replace 'your_model_name' with the name of your model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Define the path to your images\u001b[39;00m\n\u001b[0;32m      5\u001b[0m image_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGithub\u001b[39m\u001b[38;5;130;01m\\202\u001b[39;00m\u001b[38;5;124m3-24d-fai2-adsai-group-cv5\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124maw\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mrain\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mrain\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# replace with the actual path to your images\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Github/2023-24d-fai2-adsai-group-cv5\\src\\models\\model_work.py:31\u001b[0m, in \u001b[0;36mModelWork.load_model\u001b[1;34m(self, model_name)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m     22\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m    Load a trained model.\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m    - model: The loaded model\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodelling\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.keras\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mf1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miou\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43miou\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jakub\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Jakub\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\saving\\save.py:226\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 226\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[0;32m    227\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m         )\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(\n\u001b[0;32m    232\u001b[0m             filepath_str, \u001b[38;5;28mcompile\u001b[39m, options\n\u001b[0;32m    233\u001b[0m         )\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at e:\\Github\\2023-24d-fai2-adsai-group-cv5\\models\\your_model_name.keras"
     ]
    }
   ],
   "source": [
    "# Load your trained model\n",
    "model = model_work.load_model('best_model_root_masks')  # replace 'your_model_name' with the name of your model\n",
    "\n",
    "# Define the path to your images\n",
    "image_folder = 'E:/Github/2023-24d-fai2-adsai-group-cv5/data/raw/train/train'  # replace with the actual path to your images\n",
    "\n",
    "# Loop over your images\n",
    "for image_file in os.listdir(image_folder):\n",
    "    # Read the image\n",
    "    image = cv2.imread(os.path.join(image_folder, image_file))\n",
    "\n",
    "    # Predict the mask for the image\n",
    "    predicted_mask = model_work.predict_image(image, model)\n",
    "\n",
    "    # Now you can use the predicted_mask for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cv2.imread('../../Dataset/train_cropped/048_43-14-ROOT1-2023-08-08_pvd_OD0001_col-0_01-Fish Eye Corrected.png')\n",
    "test = test /255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('../best_models/best_model_root.h5', custom_objects={'f1': f1, 'iou':iou})\n",
    "def predict_image(img, patch_size):\n",
    "    img = padder(img, patch_size)\n",
    "    patches = patchify(img, (patch_size, patch_size, 3), step=patch_size)\n",
    "    patch_x = patches.shape[0]\n",
    "    patch_y = patches.shape[1]\n",
    "    patches = patches.reshape(-1, patch_size, patch_size, 3)\n",
    "    preds = model.predict(patches)\n",
    "    preds = preds.reshape(patch_x, patch_y, patch_size, patch_size)\n",
    "    predicted_mask = unpatchify(preds, (img.shape[0], img.shape[1]))\n",
    "    predicted_mask = predicted_mask > 0.85\n",
    "    plt.imshow(predicted_mask)\n",
    "    print(np.max(preds))\n",
    "    # iou_value = iou(K.variable(labels), K.variable(preds))\n",
    "    # iou_value = K.eval(iou_value)\n",
    "    # print(\"IoU:\", iou_value)\n",
    "    return predicted_mask, preds, patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_mask, preds, patches=predict_image(test,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_iou(mask_image, prediction, patch_size=256):\n",
    "    mask = cv2.imread(mask_image, 0)\n",
    "    mask_pad = padder(mask, patch_size)\n",
    "    reshaped_img = mask_pad.reshape((1,) + mask_pad.shape + (1,))\n",
    "   \n",
    "    binary_pred = prediction > 0.6\n",
    "    pred = np.array(binary_pred, dtype=np.uint8)\n",
    "    reshaped_pred = pred.reshape((1,) + pred.shape + (1,))\n",
    "   \n",
    "    reshaped_img = tf.cast(reshaped_img, dtype=tf.float32)\n",
    "    reshaped_pred = tf.cast(reshaped_pred, dtype=tf.float32)\n",
    "   \n",
    "    iou_score = iou(reshaped_img, reshaped_pred)\n",
    "   \n",
    "    return iou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert predicted_mask to np.uint8\n",
    "predicted_mask_uint8 = (predicted_mask > threshold).astype(np.uint8) * 255\n",
    "\n",
    "\n",
    "# Find connected components\n",
    "retval, labels, stats, centroids = cv2.connectedComponentsWithStats(predicted_mask_uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find connected components\n",
    "retval, labels, stats, centroids = cv2.connectedComponentsWithStats(predicted_mask_uint8)\n",
    "\n",
    "# Set area and top edge position thresholds\n",
    "area_threshold = 1200\n",
    "top_threshold = 600\n",
    "\n",
    "\n",
    "# Find the indices of the connected components based on area\n",
    "area_indices = np.where(stats[1:, cv2.CC_STAT_AREA] >= area_threshold)[0] + 1\n",
    "\n",
    "# Find the indices of the connected components based on top edge position\n",
    "top_indices = np.where(stats[1:, cv2.CC_STAT_TOP] <= top_threshold)[0] + 1\n",
    "\n",
    "# Take the intersection of the two sets of indices\n",
    "filtered_label_indices = np.intersect1d(area_indices, top_indices)\n",
    "\n",
    "# Sort the connected components based on their areas\n",
    "sorted_indices = np.argsort(stats[filtered_label_indices, cv2.CC_STAT_AREA])\n",
    "\n",
    "# Select the top 5 largest labels\n",
    "top_5_indices = filtered_label_indices[sorted_indices[-5:]]\n",
    "\n",
    "# Create a mask for the top 5 connected components\n",
    "top_5_components_mask = np.isin(labels, top_5_indices).astype(np.uint8) * 255\n",
    "\n",
    "# Display the original binary image, the largest connected components, and the filtered components\n",
    "plt.figure(figsize=(80, 80))\n",
    "plt.subplot(133), plt.imshow(top_5_components_mask)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import skeletonize\n",
    "skeleton = skeletonize(top_5_components_mask)\n",
    "plt.imshow(skeleton, cmap='gray')\n",
    "plt.title(\"Binary Mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find connected components in the top 5 components mask\n",
    "retval, labels, stats, centroids = cv2.connectedComponentsWithStats(top_5_components_mask)\n",
    "\n",
    "# Find the indices of the largest connected components\n",
    "largest_label_indices = np.argsort(stats[1:, cv2.CC_STAT_AREA])[:5] + 1\n",
    "\n",
    "# Create a mask for the largest connected components\n",
    "largest_components_mask = np.isin(labels, largest_label_indices).astype(np.uint8) * 255\n",
    "\n",
    "# Display the largest connected components\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.subplot(122), plt.imshow(largest_components_mask)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for label in np.unique(labels):\n",
    "    color = i + 1\n",
    "    top_5_components_mask[labels == label] = color\n",
    "    i+=1\n",
    "    print(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract individual labels from the segmented image\n",
    "unique_labels = np.unique(top_5_components_mask)\n",
    "\n",
    "# Skip the background label (assuming it's 1)\n",
    "unique_labels = unique_labels[1:]\n",
    "\n",
    "# Create a new figure for subplots\n",
    "fig, axs = plt.subplots(1, len(unique_labels), figsize=(15, 5))\n",
    "\n",
    "# Iterate through each unique label and plot the corresponding plant\n",
    "for i, label in enumerate(unique_labels):\n",
    "    # Get the connected component index for the current label\n",
    "    component_idx = label - 1  # Assuming labels start from 1\n",
    "\n",
    "    # Get the bounding box for the label from 'stats'\n",
    "    x, y, w, h = stats[component_idx, cv2.CC_STAT_LEFT], stats[component_idx, cv2.CC_STAT_TOP], \\\n",
    "                 stats[component_idx, cv2.CC_STAT_WIDTH], stats[component_idx, cv2.CC_STAT_HEIGHT]\n",
    "\n",
    "    # Calculate the new bounding box dimensions to make it 1.5 times bigger\n",
    "    scale_factor = 1.5\n",
    "    new_w = int(w * scale_factor)\n",
    "    new_h = int(h * scale_factor)\n",
    "\n",
    "    # Calculate the position to center the new bounding box within the original bounding box\n",
    "    x = max(0, x - int((new_w - w) / 2))\n",
    "    y = max(0, y - int((new_h - h) / 2))\n",
    "\n",
    "    # Ensure that the new bounding box coordinates are within the image boundaries\n",
    "    new_w = min(new_w, top_5_components_mask.shape[1] - x)\n",
    "    new_h = min(new_h, top_5_components_mask.shape[0] - y)\n",
    "\n",
    "    # Crop the region of interest from the original image\n",
    "    \n",
    "    plant_roi = top_5_components_mask[y:y + new_h, x:x + new_w]\n",
    "\n",
    "    # Save the cropped plant image\n",
    "    output_path = f'../plants_cropped/plant_{7-label}.png'\n",
    "    cv2.imwrite(output_path, plant_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(images):\n",
    "    if filename.endswith('.tif'):\n",
    "        image_base = os.path.splitext(filename)[0]\n",
    "        image_path = os.path.join(images, filename)\n",
    "        image = cv2.imread(image_path, 0)\n",
    "        image = image[:-15, 0:-100]\n",
    "        edges = cv2.Canny(image, 0, 255)\n",
    "        points = np.argwhere(edges > 0)\n",
    "        \n",
    "        y, x = points.min(axis=0)\n",
    "        w, h = points.max(axis=0)\n",
    "        \n",
    "        range_y = w - y\n",
    "        mid_x = (x + h) / 2\n",
    "\n",
    "        x = int(mid_x - range_y / 2)\n",
    "        h = int(mid_x + range_y / 2)\n",
    "\n",
    "        roi = image[y:w,x:h]\n",
    "\n",
    "        cv2.imwrite(f'./cropped/{filename}',roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the model outside the loop\n",
    "model = tf.keras.models.load_model('../best_models/best_model_root.h5', custom_objects={'f1': f1, 'iou': iou})\n",
    "\n",
    "# Specify folder path\n",
    "folder_path = '../task_8_files/Kaggle Dataset/cropped/'\n",
    "\n",
    "# Initialize the results list outside the loop\n",
    "results = []\n",
    "part_bounding_boxes = {}\n",
    "# Loop through all image files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(('.tif')):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Load the image\n",
    "        img = cv2.imread(file_path)\n",
    "\n",
    "        # Run the prediction function\n",
    "        predicted_mask = predict_image(img, 256, model)\n",
    "        # kernel = np.ones((4, 4), np.uint8)\n",
    "        # predicted_mask = cv2.dilate(predicted_mask, kernel, iterations=1)\n",
    "        # predicted_mask = cv2.erode(predicted_mask, kernel, iterations=1)\n",
    "\n",
    "        # Apply connected components analysis and cropping code here\n",
    "        predicted_mask_uint8 = (predicted_mask > 0.05).astype(np.uint8)\n",
    "        preds = np.array(predicted_mask_uint8, dtype=np.uint8)\n",
    "\n",
    "        # Find connected components\n",
    "        retval, labels, stats, centroids = cv2.connectedComponentsWithStats(preds)\n",
    "\n",
    "        # Sort components based on area in descending order\n",
    "        sorted_components = sorted(range(1, retval), key=lambda x: stats[x, cv2.CC_STAT_AREA], reverse=True)\n",
    "\n",
    "        # Define specific criteria\n",
    "        min_area = 200\n",
    "        min_top = 300\n",
    "        max_top = 1000\n",
    "        max_left = 2600\n",
    "\n",
    "        # Select only components meeting specific criteria\n",
    "        selected_components = [\n",
    "            i for i in sorted_components if\n",
    "            min_area <= stats[i, cv2.CC_STAT_AREA] and\n",
    "            min_top <= stats[i, cv2.CC_STAT_TOP] <= max_top and\n",
    "            max_left >= stats[i, cv2.CC_STAT_LEFT] <= max_left\n",
    "        ]\n",
    "\n",
    "        # Create an empty array for the filtered image with unique labels for each part\n",
    "        filtered_image = np.zeros_like(labels, dtype=np.uint8)\n",
    "\n",
    "        # Create a dictionary to store the bounding box with the maximum area for each part_number\n",
    "        part_boxes = {}\n",
    "\n",
    "        # Calculate the height of each part\n",
    "        height, width, _ = img.shape\n",
    "        part_width = (width // 5) - 30\n",
    "\n",
    "        # If no components were selected, create results with length 0 for all parts\n",
    "        if not selected_components:\n",
    "            for part_number in range(1, 6):\n",
    "                result_dict = {\n",
    "                    'Plant ID': f\"{os.path.splitext(file_name)[0]}_plant_{part_number}\",\n",
    "                    'Length (px)': 0\n",
    "                }\n",
    "                results.append(result_dict)\n",
    "        else:\n",
    "            # Draw bounding boxes with the maximum area for each part_number\n",
    "            for idx, component_idx in enumerate(selected_components, start=1):\n",
    "                x, y, w, h = stats[component_idx, cv2.CC_STAT_LEFT], stats[component_idx, cv2.CC_STAT_TOP], \\\n",
    "                            stats[component_idx, cv2.CC_STAT_WIDTH], stats[component_idx, cv2.CC_STAT_HEIGHT]\n",
    "\n",
    "                # Calculate part number based on the y-coordinate\n",
    "                part_number = min(x // part_width + 1, 5)\n",
    "\n",
    "                # Update the bounding box if it has a larger area and is within the allowed region\n",
    "                if part_number not in part_boxes or \\\n",
    "                        (w * h > part_boxes[part_number][2] * part_boxes[part_number][3] and\n",
    "                         x >= (part_number - 1) * part_width and x <= part_number * part_width):\n",
    "                    part_boxes[part_number] = ((x, y, w, h))\n",
    "\n",
    "                filtered_image[labels == component_idx] = part_number\n",
    "            # Loop through all selected components\n",
    "            for idx, component_idx in enumerate(selected_components, start=1):\n",
    "                x, y, w, h = stats[component_idx, cv2.CC_STAT_LEFT], stats[component_idx, cv2.CC_STAT_TOP], \\\n",
    "                            stats[component_idx, cv2.CC_STAT_WIDTH], stats[component_idx, cv2.CC_STAT_HEIGHT]\n",
    "\n",
    "                # Calculate part number based on the y-coordinate\n",
    "                part_number = min(x // part_width + 1, 5)\n",
    "                # If the part_number is not in the dictionary, initialize the bounding box\n",
    "                if part_number not in part_bounding_boxes:\n",
    "                    part_bounding_boxes[part_number] = [x, y, x + w, y + h]\n",
    "                else:\n",
    "                    # Update bounding box if the part_number already exists in the dictionary\n",
    "                    part_bounding_boxes[part_number][0] = min(part_bounding_boxes[part_number][0], x)\n",
    "                    part_bounding_boxes[part_number][1] = min(part_bounding_boxes[part_number][1], y)\n",
    "                    part_bounding_boxes[part_number][2] = max(part_bounding_boxes[part_number][2], x + w)\n",
    "                    part_bounding_boxes[part_number][3] = max(part_bounding_boxes[part_number][3], y + h)\n",
    "\n",
    "            # Draw merged bounding boxes and annotate with part numbers\n",
    "            for part_number, bbox in part_bounding_boxes.items():\n",
    "                x_min, y_min, x_max, y_max = bbox\n",
    "                cv2.rectangle(img, (x_min, y_min), (x_max, y_max), (0, 0, 255), 3)\n",
    "                cv2.putText(img, str(part_number), (x_min + (x_max - x_min) // 2 - 10, y_min - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 10, (0, 0, 255), 10)\n",
    "\n",
    "            # Initialize a dictionary to store file names for each part_number\n",
    "            file_names_by_part = {}\n",
    "\n",
    "            # Draw bounding boxes with the maximum area for each part_number\n",
    "            for part_number, box in part_boxes.items():\n",
    "                \n",
    "                x, y, w, h = box\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 3)\n",
    "                cv2.putText(img, str(part_number), (x + w // 2 - 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 10, (0, 0, 255), 10)\n",
    "\n",
    "                # Store file name for each part_number\n",
    "                file_names_by_part[part_number] = file_name\n",
    "\n",
    "            # Crop bounding boxes on the filtered_image\n",
    "            cropped_roots = []\n",
    "            for part_number, box in part_boxes.items():\n",
    "                x, y, w, h = box\n",
    "                cropped_root = filtered_image[y:y+h, x:x+w]\n",
    "                cropped_roots.append(cropped_root)\n",
    "           \n",
    "            # Skeletonize each cropped root\n",
    "            skeletonized_roots = [skeletonize(root > 0) for root in cropped_roots]\n",
    "            \n",
    "            # Calculate the length of each main root and append to the results list\n",
    "            for part_number in range(1, 6):\n",
    "                if part_number <= len(skeletonized_roots) and part_number in part_boxes:\n",
    "                    # Create subplot\n",
    "                    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "                    \n",
    "                    skeleton = skeletonized_roots[part_number - 1]\n",
    "                    test = summarize(Skeleton(skeleton))\n",
    "                    length = calculate_length(skeleton, test)\n",
    "                    \n",
    "                    ax.imshow(skeleton, cmap='gray')\n",
    "                    # Plot circle for the end of the main root\n",
    "                    main_max = test['node-id-dst'].idxmax()\n",
    "                    x_coord_dst = test.loc[main_max, 'image-coord-dst-1']\n",
    "                    y_coord_dst = test.loc[main_max, 'image-coord-dst-0']\n",
    "                    ax.add_patch(plt.Circle((x_coord_dst, y_coord_dst), radius=10, color='gray', fill=False))\n",
    "\n",
    "                    # Plot circle for the beginning of the main root\n",
    "                    main_min = test['node-id-src'].idxmin()\n",
    "                    x_coord_src = test.loc[main_min, 'image-coord-src-1']\n",
    "                    y_coord_src = test.loc[main_min, 'image-coord-src-0']\n",
    "                    ax.add_patch(plt.Circle((x_coord_src, y_coord_src), radius=10, color='green', fill=False))\n",
    "                    ax.set_aspect('equal', 'box')\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    length = 0\n",
    "\n",
    "                file_name_for_part = os.path.splitext(file_names_by_part.get(part_number, file_name))[0]  # Remove file extension\n",
    "\n",
    "                # Append results to the list\n",
    "                result_dict = {\n",
    "                    'Plant ID': f\"{file_name_for_part}_plant_{part_number}\",\n",
    "                    'Length (px)': length\n",
    "                }\n",
    "                results.append(result_dict)\n",
    "\n",
    "                print(f\"Root Length for Plant {part_number}: {length}\")\n",
    "                \n",
    "# Create a DataFrame with columns \"Plant ID\" and \"Length (px)\"\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Check if the CSV file already exists\n",
    "csv_filename = '../task_8_files/Kaggle Dataset/kaggle.csv'\n",
    "file_exists = os.path.exists(csv_filename)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(csv_filename, index=False, mode='a', header=not file_exists)\n",
    "\n",
    "print(f\"Results saved to {csv_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
